{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:    \n",
    "[x] SoftmaxLinearRegression    \n",
    "[ ] Neural Nets    \n",
    "[x] Class for scoring generating report stuff   \n",
    "[x] hyperparameter tuning function    \n",
    "[ ] Majority voting class (hard+soft)    \n",
    "[ ] Stacking class    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolterlw/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "### loading data\n",
    "with h5py.File('../data/mnist.hdf5','r') as f:\n",
    "    Xtr = f['Xtr'].value.reshape(-1, 28*28)\n",
    "    ytr = f['ytr'].value\n",
    "    \n",
    "    Xv = f['Xv'].value.reshape(-1, 28*28)\n",
    "    yv = f['yv'].value\n",
    "    \n",
    "    Xts = f['Xts'].value.reshape(-1, 28*28)\n",
    "    yts = f['yts'].value\n",
    "\n",
    "with h5py.File('../data/usp_processed.hdf5', 'r') as f:\n",
    "    Xusps = f['X'].value.reshape(-1, 28*28)\n",
    "    yusps = f['y'].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Evaluator():\n",
    "    def __init__(self, Xtr, ytr, Xv, yv, metrics={}):\n",
    "        self.dat_tr = (Xtr, ytr)\n",
    "        self.dat_v = (Xv, yv)\n",
    "        self.metrics = metrics\n",
    "        \n",
    "    def score(self, model):\n",
    "        pred_tr = model.predict(self.dat_tr[0])\n",
    "        pred_v = model.predict(self.dat_v[0])\n",
    "        \n",
    "        res = {}\n",
    "        for k,v in self.metrics.items():\n",
    "            res[k + '_tr'] = v(self.dat_tr[1], pred_tr)\n",
    "            res[k + '_v'] = v(self.dat_v[1], pred_v)\n",
    "        return res\n",
    "    \n",
    "    def score_test(self, model, Xts, yts):\n",
    "        pred = model.predict(Xts)\n",
    "        res = {}\n",
    "        for k,v in self.metrics.items():\n",
    "            res[k + '_ts'] = v(yts, pred)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperparamSearch():\n",
    "    def __init__(self, Xtr, ytr, Xv, yv, score_func):\n",
    "        self.dat_tr = (Xtr, ytr)\n",
    "        self.dat_v = (Xv, yv)\n",
    "        self.f_score = score_func\n",
    "        \n",
    "    def tune(self, model_class, args=[], param_var=[], fit_params={}): \n",
    "        scores = []\n",
    "        for p in param_var:\n",
    "            model = model_class(*args, **p)\n",
    "            model.fit(*self.dat_tr, **fit_params)\n",
    "            scores.append(self.f_score(model))\n",
    "        amax = np.argmax(scores)\n",
    "        return scores[amax], param_var[amax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ev_full = Evaluator(Xtr, ytr, Xv, yv, metrics={'acc': accuracy_score, 'conf_m': confusion_matrix})\n",
    "ev_comp = Evaluator(Xtr, ytr, Xv, yv, metrics={'acc': accuracy_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hypp_s = HyperparamSearch(Xtr, ytr, Xv, yv, lambda x: ev_comp.score(x)['acc_v'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dill.dump_session('./jupyter_session.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### implementing softmax regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from linear_model import SoftmaxRegression, Batcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "batcher = Batcher(256, one_hot=True)\n",
    "args = (Xtr.shape[1], 10)\n",
    "param_var = [{'lr': 0.01, 'fit_intercept': True},\n",
    "             {'lr': 0.05, 'fit_intercept': True},\n",
    "             {'lr': 0.1, 'fit_intercept': True}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e96f1c51c7da44e8879feb40c8ed7314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9330968668a544a392e277fa91dd2036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7daa207de26d420fabb0fd23605cde4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9197, {'fit_intercept': True, 'lr': 0.1})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypp_s.tune(SoftmaxRegression, args, param_var, {'batch_generator': batcher, 'n_epochs': 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ceacc96b7d84bad9600ccbcf502da0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<linear_model.SoftmaxRegression at 0x7f601ff691d0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr = SoftmaxRegression(*args, lr=0.1, fit_intercept=True)\n",
    "sr.fit(Xtr, ytr, batch_generator=batcher, n_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc_ts': 0.9168,\n",
       " 'conf_m_ts': array([[ 959,    0,    2,    3,    0,    6,    8,    1,    1,    0],\n",
       "        [   0, 1107,    4,    1,    0,    1,    4,    2,   16,    0],\n",
       "        [   6,   12,  907,   23,   11,    4,   14,   12,   37,    6],\n",
       "        [   4,    0,   23,  920,    1,   23,    4,    9,   17,    9],\n",
       "        [   3,    3,    6,    1,  905,    0,    9,    4,   13,   38],\n",
       "        [   9,    3,    2,   48,    8,  764,   18,    3,   32,    5],\n",
       "        [  13,    3,    7,    2,   10,   15,  899,    4,    5,    0],\n",
       "        [   3,    8,   20,   11,    9,    1,    0,  944,    2,   30],\n",
       "        [   6,   10,   11,   27,    8,   22,   15,   12,  855,    8],\n",
       "        [   7,    6,    2,    9,   37,    7,    0,   23,   10,  908]])}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev_full.score_test(sr, Xts, yts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc_ts': 0.36036801840092003,\n",
       " 'conf_m_ts': array([[ 459,    1,  124,  461,    7,  890,   14,   12,   27,    5],\n",
       "        [  15, 1372,   67,  151,   18,  179,   31,   51,  112,    4],\n",
       "        [  43,    6,  841,  548,   31,  361,  118,   19,   29,    3],\n",
       "        [  19,    5,   94, 1508,   12,  269,    7,   42,   29,   15],\n",
       "        [  36,   51,  104,   76, 1061,  117,  128,  114,  143,  170],\n",
       "        [  96,   13,   86,  509,   45,  985,  128,   57,   67,   14],\n",
       "        [  59,    5,  291,  337,   53,  890,  290,    8,   66,    1],\n",
       "        [  65,  111,  375,  923,   16,  156,   45,  175,  105,   29],\n",
       "        [ 119,   35,  131,  637,   27,  594,   89,   14,  347,    7],\n",
       "        [  48,  141,  122,  577,  181,  119,   39,  461,  143,  169]])}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev_full.score_test(sr, Xusps, yusps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm = SVC(kernel='linear', max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolterlw/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=500, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(Xtr, ytr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_var = [\n",
    "    {'n_estimators': 50, 'max_depth': 8, 'n_jobs': -1},\n",
    "    {'n_estimators': 50, 'max_depth': 15, 'n_jobs': -1},\n",
    "    {'n_estimators': 100, 'max_depth': 8, 'n_jobs': -1},\n",
    "    {'n_estimators': 100, 'max_depth': 8, 'min_samples_split': 10, 'n_jobs': -1},\n",
    "    {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 15, 'n_jobs': -1},\n",
    "    {'n_estimators': 100, 'max_depth': 15, 'min_samples_split': 15, 'n_jobs': -1},\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9669, {'max_depth': 15, 'n_estimators': 50, 'n_jobs': -1})"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypp_s.tune(RandomForestClassifier, (), param_var, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth=15, n_estimators=50, n_jobs=-1)\n",
    "rf.fit(Xtr, ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc_ts': 0.9623,\n",
       " 'conf_m_ts': array([[ 972,    1,    0,    0,    0,    3,    1,    1,    2,    0],\n",
       "        [   0, 1125,    2,    2,    1,    2,    2,    0,    1,    0],\n",
       "        [   7,    1,  988,   10,    4,    1,    4,   10,    6,    1],\n",
       "        [   1,    0,   11,  963,    0,   14,    0,   10,    7,    4],\n",
       "        [   2,    1,    1,    1,  943,    0,    4,    1,    4,   25],\n",
       "        [   4,    2,    1,   19,    2,  842,    7,    3,    8,    4],\n",
       "        [   7,    3,    1,    0,    4,    4,  934,    0,    5,    0],\n",
       "        [   2,    3,   20,    1,    4,    0,    0,  976,    3,   19],\n",
       "        [   5,    2,    3,   13,    7,    4,    3,    4,  922,   11],\n",
       "        [   8,    7,    2,    7,   10,    6,    0,    4,    7,  958]])}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev_full.score_test(rf, Xts, yts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc_ts': 0.5130756537826892,\n",
       " 'conf_m_ts': array([[1594,   23,   39,   57,    9,  155,   37,   73,    8,    5],\n",
       "        [   2, 1830,    8,   12,    5,   27,   66,   48,    2,    0],\n",
       "        [  86,  144, 1130,  118,  103,  193,   61,  157,    7,    0],\n",
       "        [  24,   54,   53, 1293,   90,  241,    3,  236,    2,    4],\n",
       "        [  39,  220,   54,   17, 1351,   64,   38,  175,   21,   21],\n",
       "        [  51,   51,   46,  174,   87, 1310,   49,  222,    8,    2],\n",
       "        [ 206,   98,  144,   96,  117,  549,  526,  241,   22,    1],\n",
       "        [  42,  434,  463,  190,   36,   36,   38,  749,    8,    4],\n",
       "        [  43,  168,  153,  228,  144,  646,  119,   63,  433,    3],\n",
       "        [  17,  209,   81,  122,  723,   64,   28,  681,   30,   45]])}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev_full.score_test(rf, Xusps, yusps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input(shape=(28*28,))\n",
    "\n",
    "x = Dense(350, activation='relu', kernel_regularizer='l2')(inp)\n",
    "x = Dense(170, activation='relu')(x)\n",
    "out = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=[inp], outputs=[out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DNN():\n",
    "    def __init__(self, hidden_sizes=[], activation='relu', regularizers=[], lr=0.01):\n",
    "        inp = Input(shape=(28*28,))\n",
    "        x = inp\n",
    "        for hs,reg in zip(hidden_sizes, regularizers):\n",
    "            x = Dense(hs, activation=activation, kernel_regularizer=reg)(x)\n",
    "        out = Dense(10, activation='softmax')(x)\n",
    "        self.model = Model(inputs=[inp], outputs=[out])\n",
    "        self.model.compile(Adam(lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    def fit(self, X, y, **kwargs):\n",
    "        yoh = to_categorical(y)\n",
    "        self.model.fit(X, yoh, **kwargs)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.argmax(\n",
    "            self.model.predict(X),\n",
    "            axis=1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dnn = DNN([350, 170], regularizers=['l2',None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_var = [\n",
    "    {'hidden_sizes': [100, 50], 'activation': 'relu', 'regularizers': [None, None]},\n",
    "    {'hidden_sizes': [250, 100], 'activation': 'relu', 'regularizers': [None, None]},\n",
    "    {'hidden_sizes': [250, 100], 'activation': 'relu', 'regularizers': ['l2', None]},\n",
    "    {'hidden_sizes': [350, 150], 'activation': 'relu', 'regularizers': ['l2', None]},\n",
    "    {'hidden_sizes': [350, 150], 'activation': 'relu', 'regularizers': ['l2', 'l2']},\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9754,\n",
       " {'activation': 'relu',\n",
       "  'hidden_sizes': [100, 50],\n",
       "  'regularizers': [None, None]})"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypp_s.tune(DNN, param_var=param_var, fit_params={'batch_size': 512, 'epochs': 30, 'verbose': False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, BatchNormalization, MaxPool2D, ReLU, Concatenate, Dropout, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5():\n",
    "    def __init__(self):\n",
    "        inp = Input(shape=(28,28,1))\n",
    "        x = Conv2D(6, kernel_size=5, strides = 1, activation = 'relu')(inp)\n",
    "        x = MaxPool2D(2, strides = 2)(x)\n",
    "        x = Conv2D(16, kernel_size=5, strides = 1, activation = 'relu')(x)\n",
    "        x = MaxPool2D(2, strides=2)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(120, activation='relu')(x)\n",
    "        x = Dense(84, activation='relu')(x)\n",
    "        out = Dense(10, activation='softmax')(x)\n",
    "\n",
    "        self.model = Model(inputs=[inp], outputs=[out])\n",
    "        self.model.compile('Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    def fit(self, X, y, **kwargs):\n",
    "        yoh = to_categorical(y)\n",
    "        Xim = X.reshape(-1,28,28,1)\n",
    "        self.model.fit(Xim, yoh, **kwargs)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.argmax(\n",
    "            self.model.predict(X.reshape(-1,28,28,1)),\n",
    "            axis = 1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet = LeNet5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 27s 548us/step - loss: 0.2500 - acc: 0.9269 - val_loss: 0.1810 - val_acc: 0.9494\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 27s 548us/step - loss: 0.1630 - acc: 0.9509 - val_loss: 0.1340 - val_acc: 0.9611\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 27s 545us/step - loss: 0.1263 - acc: 0.9624 - val_loss: 0.1116 - val_acc: 0.9673\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 27s 545us/step - loss: 0.1051 - acc: 0.9684 - val_loss: 0.1049 - val_acc: 0.9694\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 28s 553us/step - loss: 0.0896 - acc: 0.9729 - val_loss: 0.0846 - val_acc: 0.9737\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 27s 547us/step - loss: 0.0809 - acc: 0.9753 - val_loss: 0.0819 - val_acc: 0.9754\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 27s 548us/step - loss: 0.0704 - acc: 0.9784 - val_loss: 0.0750 - val_acc: 0.9780\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 27s 548us/step - loss: 0.0634 - acc: 0.9809 - val_loss: 0.0699 - val_acc: 0.9794\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 28s 553us/step - loss: 0.0586 - acc: 0.9819 - val_loss: 0.0673 - val_acc: 0.9813\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 27s 549us/step - loss: 0.0558 - acc: 0.9833 - val_loss: 0.0629 - val_acc: 0.9820\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 28s 555us/step - loss: 0.0508 - acc: 0.9840 - val_loss: 0.0642 - val_acc: 0.9808\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 27s 549us/step - loss: 0.0472 - acc: 0.9853 - val_loss: 0.0602 - val_acc: 0.9829\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 27s 550us/step - loss: 0.0434 - acc: 0.9861 - val_loss: 0.0558 - val_acc: 0.9840\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 27s 550us/step - loss: 0.0391 - acc: 0.9877 - val_loss: 0.0526 - val_acc: 0.9847\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 28s 554us/step - loss: 0.0359 - acc: 0.9890 - val_loss: 0.0553 - val_acc: 0.9846\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 28s 552us/step - loss: 0.0337 - acc: 0.9893 - val_loss: 0.0546 - val_acc: 0.9848\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 28s 554us/step - loss: 0.0317 - acc: 0.9901 - val_loss: 0.0508 - val_acc: 0.9853\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 28s 554us/step - loss: 0.0296 - acc: 0.9909 - val_loss: 0.0478 - val_acc: 0.9871\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 28s 550us/step - loss: 0.0279 - acc: 0.9914 - val_loss: 0.0488 - val_acc: 0.9858\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 28s 554us/step - loss: 0.0266 - acc: 0.9916 - val_loss: 0.0480 - val_acc: 0.9866\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 28s 557us/step - loss: 0.0234 - acc: 0.9928 - val_loss: 0.0491 - val_acc: 0.9870\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 28s 553us/step - loss: 0.0228 - acc: 0.9929 - val_loss: 0.0528 - val_acc: 0.9856\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 28s 550us/step - loss: 0.0236 - acc: 0.9921 - val_loss: 0.0541 - val_acc: 0.9851\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 27s 550us/step - loss: 0.0204 - acc: 0.9933 - val_loss: 0.0476 - val_acc: 0.9867\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 28s 552us/step - loss: 0.0192 - acc: 0.9936 - val_loss: 0.0465 - val_acc: 0.9880\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 28s 556us/step - loss: 0.0181 - acc: 0.9941 - val_loss: 0.0508 - val_acc: 0.9866\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 28s 552us/step - loss: 0.0160 - acc: 0.9950 - val_loss: 0.0459 - val_acc: 0.9881\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 28s 555us/step - loss: 0.0160 - acc: 0.9948 - val_loss: 0.0481 - val_acc: 0.9874\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 28s 552us/step - loss: 0.0157 - acc: 0.9951 - val_loss: 0.0465 - val_acc: 0.9884\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 28s 553us/step - loss: 0.0139 - acc: 0.9957 - val_loss: 0.0470 - val_acc: 0.9878\n"
     ]
    }
   ],
   "source": [
    "lenet.fit(Xtr, ytr, batch_size=512, epochs=30, validation_data=(Xv.reshape(-1,28,28,1), to_categorical(yv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc_ts': 0.9891,\n",
       " 'conf_m_ts': array([[ 971,    0,    0,    0,    0,    0,    3,    2,    2,    2],\n",
       "        [   0, 1130,    2,    0,    0,    0,    2,    1,    0,    0],\n",
       "        [   1,    1, 1025,    1,    0,    0,    1,    1,    2,    0],\n",
       "        [   0,    0,    1, 1005,    0,    4,    0,    0,    0,    0],\n",
       "        [   0,    0,    0,    0,  970,    0,    1,    2,    0,    9],\n",
       "        [   1,    0,    0,    7,    0,  880,    2,    1,    0,    1],\n",
       "        [   4,    2,    0,    0,    1,    3,  947,    0,    1,    0],\n",
       "        [   1,    2,    8,    2,    0,    0,    0, 1014,    0,    1],\n",
       "        [   3,    0,    5,    3,    0,    1,    0,    1,  961,    0],\n",
       "        [   1,    1,    1,    6,    3,    3,    0,    2,    4,  988]])}"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev_full.score_test(lenet, Xts, yts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc_ts': 0.8288414420721036,\n",
       " 'conf_m_ts': array([[1858,    2,   27,    6,    0,   16,   36,    3,   33,   19],\n",
       "        [  13, 1954,    5,    0,    0,    0,    8,    7,   12,    1],\n",
       "        [  25,   17, 1698,  102,    2,   84,   23,    7,   39,    2],\n",
       "        [   3,    4,   18, 1909,    3,   54,    0,    3,    4,    2],\n",
       "        [  11,   13,   21,    6, 1724,    4,   46,  104,   47,   24],\n",
       "        [  22,    5,   13,   92,    2, 1680,   17,   72,   72,   25],\n",
       "        [  67,    5,   56,    3,    0,   22, 1808,    0,   39,    0],\n",
       "        [  19,  143,  195,   84,   12,    5,    0, 1512,   21,    9],\n",
       "        [  11,    8,   40,   64,   13,   87,   17,   43, 1712,    5],\n",
       "        [   3,   34,    9,   35,  419,    4,   10,  662,  103,  721]])}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev_full.score_test(lenet, Xusps, yusps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DenseNet-ish thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dense_block(filters=32, kernel_size=3):\n",
    "    def f(x):\n",
    "        x0 = BatchNormalization()(x)\n",
    "        x0 = ReLU()(x0)\n",
    "        x0 = Conv2D(filters, kernel_size=3, padding='same')(x0)\n",
    "        x0 = Dropout(0.2)(x0)\n",
    "        x0 = BatchNormalization()(x0)\n",
    "        x0 = ReLU()(x0)\n",
    "        x = Concatenate()([x, x0])\n",
    "        return x\n",
    "    return f\n",
    "    \n",
    "def bottleneck(filters=32):\n",
    "    def f(x):\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D(filters, kernel_size=1, padding='same')(x)\n",
    "        x = MaxPool2D()(x)\n",
    "        return x\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DenseNet():\n",
    "    def __init__(self, filters=[], dense_layers=[]):\n",
    "        inp = Input(shape=(28, 28, 1))\n",
    "        x = inp\n",
    "        for flt in filters:\n",
    "            x = dense_block(flt, 3)(x)\n",
    "            x = bottleneck(flt//2)(x)\n",
    "        \n",
    "        x = Flatten()(x)\n",
    "        \n",
    "        for dl in dense_layers:\n",
    "            x = Dense(dl, activation='relu')(x)\n",
    "\n",
    "        out = Dense(10, activation='softmax')(x)\n",
    "        \n",
    "        self.model = Model(inputs=[inp], outputs=[out])\n",
    "        self.model.compile('Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    def fit(self, X, y, **kwargs):\n",
    "        yoh = to_categorical(y)\n",
    "        Xim = X.reshape(-1,28,28,1)\n",
    "        self.model.fit(Xim, yoh, **kwargs)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.argmax(\n",
    "            self.model.predict(X.reshape(-1,28,28,1)),\n",
    "            axis = 1\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "inp = Input(shape=(28, 28,1))\n",
    "\n",
    "x = dense_block(64, 3)(inp)\n",
    "x = bottleneck(32)(x)\n",
    "x = dense_block(32, 3)(x)\n",
    "x = bottleneck(16)(x)\n",
    "x = dense_block(16, 3)\n",
    "x  = bottl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet = DenseNet(filters = [32, 16], dense_layers=[32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 372s 7ms/step - loss: 1.0190 - acc: 0.6732 - val_loss: 0.3033 - val_acc: 0.9092\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 370s 7ms/step - loss: 0.2569 - acc: 0.9203 - val_loss: 0.1759 - val_acc: 0.9488\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 368s 7ms/step - loss: 0.1646 - acc: 0.9489 - val_loss: 0.1401 - val_acc: 0.9591\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 368s 7ms/step - loss: 0.1229 - acc: 0.9617 - val_loss: 0.1027 - val_acc: 0.9698\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 368s 7ms/step - loss: 0.1015 - acc: 0.9684 - val_loss: 0.0843 - val_acc: 0.9754\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 367s 7ms/step - loss: 0.0879 - acc: 0.9722 - val_loss: 0.0798 - val_acc: 0.9770\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 368s 7ms/step - loss: 0.0767 - acc: 0.9758 - val_loss: 0.0848 - val_acc: 0.9741\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 367s 7ms/step - loss: 0.0696 - acc: 0.9774 - val_loss: 0.0652 - val_acc: 0.9807\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 372s 7ms/step - loss: 0.0629 - acc: 0.9806 - val_loss: 0.0682 - val_acc: 0.9800\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 389s 8ms/step - loss: 0.0584 - acc: 0.9811 - val_loss: 0.0663 - val_acc: 0.9803\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 370s 7ms/step - loss: 0.0529 - acc: 0.9829 - val_loss: 0.0631 - val_acc: 0.9806\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 369s 7ms/step - loss: 0.0513 - acc: 0.9834 - val_loss: 0.0572 - val_acc: 0.9831\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 369s 7ms/step - loss: 0.0478 - acc: 0.9848 - val_loss: 0.0559 - val_acc: 0.9840\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 369s 7ms/step - loss: 0.0462 - acc: 0.9850 - val_loss: 0.0680 - val_acc: 0.9808\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 369s 7ms/step - loss: 0.0418 - acc: 0.9866 - val_loss: 0.0550 - val_acc: 0.9851\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 369s 7ms/step - loss: 0.0394 - acc: 0.9871 - val_loss: 0.0541 - val_acc: 0.9841\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 367s 7ms/step - loss: 0.0380 - acc: 0.9879 - val_loss: 0.0500 - val_acc: 0.9859\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 369s 7ms/step - loss: 0.0356 - acc: 0.9885 - val_loss: 0.0446 - val_acc: 0.9871\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 367s 7ms/step - loss: 0.0333 - acc: 0.9892 - val_loss: 0.0451 - val_acc: 0.9871\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 366s 7ms/step - loss: 0.0325 - acc: 0.9896 - val_loss: 0.0504 - val_acc: 0.9868\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 368s 7ms/step - loss: 0.0293 - acc: 0.9901 - val_loss: 0.0494 - val_acc: 0.9867\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 371s 7ms/step - loss: 0.0304 - acc: 0.9903 - val_loss: 0.0505 - val_acc: 0.9851\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 370s 7ms/step - loss: 0.0285 - acc: 0.9907 - val_loss: 0.0484 - val_acc: 0.9872\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 370s 7ms/step - loss: 0.0271 - acc: 0.9912 - val_loss: 0.0476 - val_acc: 0.9868\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 369s 7ms/step - loss: 0.0273 - acc: 0.9915 - val_loss: 0.0490 - val_acc: 0.9872\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 367s 7ms/step - loss: 0.0245 - acc: 0.9918 - val_loss: 0.0529 - val_acc: 0.9863\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 377s 8ms/step - loss: 0.0240 - acc: 0.9917 - val_loss: 0.0504 - val_acc: 0.9858\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 389s 8ms/step - loss: 0.0222 - acc: 0.9929 - val_loss: 0.0470 - val_acc: 0.9867\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 368s 7ms/step - loss: 0.0220 - acc: 0.9932 - val_loss: 0.0449 - val_acc: 0.9874\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 369s 7ms/step - loss: 0.0214 - acc: 0.9929 - val_loss: 0.0520 - val_acc: 0.9877\n"
     ]
    }
   ],
   "source": [
    "densenet.fit(Xtr, ytr, \n",
    "             batch_size=512, epochs=30,\n",
    "             validation_data=(Xv.reshape(-1,28,28,1), to_categorical(yv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc_ts': 0.9868,\n",
       " 'conf_m_ts': array([[ 978,    0,    0,    0,    0,    0,    1,    1,    0,    0],\n",
       "        [   0, 1133,    1,    1,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,    5, 1022,    0,    0,    0,    0,    3,    0,    0],\n",
       "        [   0,    1,    5,  994,    0,    8,    0,    0,    1,    1],\n",
       "        [   0,    1,    0,    0,  971,    0,    4,    2,    0,    4],\n",
       "        [   1,    0,    1,    3,    0,  885,    1,    0,    0,    1],\n",
       "        [   8,    4,    1,    0,    2,    3,  940,    0,    0,    0],\n",
       "        [   0,    5,    6,    0,    0,    1,    0, 1015,    0,    1],\n",
       "        [   8,    3,    4,    3,    1,    2,    2,    3,  941,    7],\n",
       "        [   2,    3,    2,    1,    4,    4,    0,    4,    0,  989]])}"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev_full.score_test(densenet, Xts, yts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc_ts': 0.8177908895444772,\n",
       " 'conf_m_ts': array([[1747,   13,  121,    7,    5,   22,   28,    5,   36,   16],\n",
       "        [   1, 1979,    4,    0,    1,    2,    3,   10,    0,    0],\n",
       "        [   3,   18, 1807,   55,    1,   64,    1,   10,   38,    2],\n",
       "        [   1,    1,   39, 1814,    0,  137,    1,    5,    2,    0],\n",
       "        [   7,   66,   25,    2, 1751,    4,   25,   23,   69,   28],\n",
       "        [   0,    4,   10,  112,    1, 1844,    4,   19,    1,    5],\n",
       "        [  42,   56,  172,   10,    1,  189, 1427,    7,   94,    2],\n",
       "        [   0,  267,  603,   44,    8,   10,    1, 1040,   12,   15],\n",
       "        [   1,    7,   38,   42,    6,  205,    9,    5, 1674,   13],\n",
       "        [   6,   64,  150,   67,  190,   26,    4,  134,   87, 1272]])}"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev_full.score_test(densenet, Xusps, yusps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensambling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = [densenet, sr, lenet, rf, dnn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MajorityVoting():\n",
    "    def __init__(self, classifiers=[]):\n",
    "        self.clfs = classifiers\n",
    "    \n",
    "    def predict(self, X):\n",
    "        preds = np.c_[[clf.predict(X) for clf in self.clfs]]\n",
    "        return mode(preds.T, axis=1)[0][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mv = MajorityVoting(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_usps = mv.predict(Xusps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6741837091854592"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pred_usps == yusps).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = [densenet, lenet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mv2 = MajorityVoting(models)\n",
    "pred_usps = mv.predict(Xusps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8288414420721036"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lenet.predict(Xusps) == yusps).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6741837091854592"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pred_usps == yusps).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
