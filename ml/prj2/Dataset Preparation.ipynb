{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%store -r HUMAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if HUMAN:\n",
    "    diff = pd.read_csv('./HumanObserved-Dataset/HumanObserved-Features-Data/diffn_pairs.csv')\n",
    "    same = pd.read_csv('./HumanObserved-Dataset/HumanObserved-Features-Data/same_pairs.csv')\n",
    "else:\n",
    "    diff = pd.read_csv('./GSC-Dataset/GSC-Features-Data/diffn_pairs.csv')\n",
    "    same = pd.read_csv('./GSC-Dataset/GSC-Features-Data/same_pairs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "same['writer_A'] = same.img_id_A.str.extract(r'^([0-9]+)',expand=False)\n",
    "same['writer_B'] = same.img_id_B.str.extract(r'^([0-9]+)',expand=False)\n",
    "\n",
    "diff['writer_A'] = diff.img_id_A.str.extract(r'^([0-9]+)',expand=False)\n",
    "diff['writer_B'] = diff.img_id_B.str.extract(r'^([0-9]+)',expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_writers = set(same.writer_A.value_counts()[:5].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_test_idx(df, test_writers):\n",
    "    return df.img_id_A.str[:-1].isin(test_writers) |\\\n",
    "           df.img_id_B.str[:-1].isin(test_writers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "same_test = same[get_test_idx(same, test_writers)].copy()\n",
    "same.drop(get_test_idx(same, test_writers),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diff_test = diff[get_test_idx(diff, test_writers)].copy()\n",
    "diff.drop(get_test_idx(diff, test_writers), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full = pd.concat([same, diff])\n",
    "full_test = pd.concat([same_test, diff_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test separation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Img](https://d1b10bmlvqabco.cloudfront.net/attach/jlbcueow34qdq/isamd3soc56z/jnj25zqee36h/Screen_Shot_20181021_at_11.59.46_AM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scheme 1 Unseen writers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for now any pair with test writer is considered a test pair    \n",
    "    for more check [link](https://piazza.com/class/jlbcueow34qdq?cid=338)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def partition_unseen(df, train_writers=0.6):\n",
    "    A = list(set(df.writer_A))\n",
    "    np.random.shuffle(A)\n",
    "\n",
    "    wr_train = set(A[:int(len(A)*train_writers)])\n",
    "    wr_test = set(A[int(len(A)*train_writers):])\n",
    "\n",
    "    df['test'] = (df.writer_A.isin(wr_test) | df.writer_B.isin(wr_test)).astype('uint8')\n",
    "\n",
    "    df_tr = df[df.test == 0].drop(['test'],axis=1)\n",
    "    df_ts = df[df.test == 1].drop(['test'],axis=1)\n",
    "    df.drop('test',axis=1,inplace=True)\n",
    "    print(f\"target distribution in first: {df_tr.target.mean():.5f}\")\n",
    "    print(f\"target distribution in second: {df_ts.target.mean():.5f}\")\n",
    "    return df_tr, df_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target distribution in first: 0.00454\n",
      "target distribution in second: 0.00171\n"
     ]
    }
   ],
   "source": [
    "u_tr, u_v = partition_unseen(full, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder = 'human/' if HUMAN else 'gsc/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_test.to_csv('./data/'+folder+'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u_tr.to_csv('./data/' + folder + 'unseen_train.csv')\n",
    "u_v.to_csv('./data/' + folder + 'unseen_valid.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scheme 2 Shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def partition_shuffled(df, train_writers=0.8):\n",
    "    shuffled = df.sample(frac=1)\n",
    "    breakpoint = int(train_writers * df.shape[0])\n",
    "    df_tr = shuffled.iloc[:breakpoint]\n",
    "    df_ts = shuffled.iloc[breakpoint:]\n",
    "    print(f\"target distribution in train: {df_tr.target.mean():.5f}\")\n",
    "    print(f\"target distribution in test: {df_ts.target.mean():.5f}\")\n",
    "    return df_tr, df_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_tr, r_v = partition_shuffled(full, 0.6)\n",
    "\n",
    "r_tr.to_csv('./data/' + folder + 'random_train.csv')\n",
    "r_v.to_csv('./data/' + folder + 'random_valid.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scheme 3 Seen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "once again not completely clear how to treat pairs of users    \n",
    "let's see how many duplicated pairs we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full[['writer_A','writer_B']].duplicated().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "that's enought to partitiob by pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def partition_seen(df, train_writers=0.8):\n",
    "    df_s = df.sort_values(by=['writer_A','writer_B'])\n",
    "    pairs = (df_s.writer_A + '_').str.cat(df_s.writer_B).reset_index().drop(['index'],axis=1)\n",
    "    pairs.columns = ['pair']\n",
    "    pairs['idx'] = pairs.groupby(by='pair').cumcount()\n",
    "    pairs = pairs.merge(\n",
    "    (pairs.groupby('pair')['idx'].count() * train_writers).reset_index(),\n",
    "    how='left',\n",
    "    on='pair', suffixes=('_cum','_thr')\n",
    "    )\n",
    "    df_tr = df_s[(pairs.idx_cum <= pairs.idx_thr).values]\n",
    "    df_ts = df_s[(pairs.idx_cum > pairs.idx_thr).values]\n",
    "    \n",
    "    print(f\"first size: {df_tr.shape[0] / df.shape[0]}\")\n",
    "    print(f\"second size: {df_ts.shape[0] / df.shape[0]}\")\n",
    "    \n",
    "    print(f\"first distribution in train: {df_tr.target.mean():.5f}\")\n",
    "    print(f\"second distribution in test: {df_ts.target.mean():.5f}\")\n",
    "    return df_tr, df_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s_tr, s_v = partition_seen(full, train_writers=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s_tr.to_csv('./data/' + folder + 'seen_train.csv')\n",
    "s_v.to_csv('./data/' + folder + 'seen_valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
